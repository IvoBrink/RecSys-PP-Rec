{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T07:58:56.802485Z",
     "start_time": "2024-06-11T07:58:50.812875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NewsContent import *\n",
    "from UserContent import *\n",
    "from preprocessing import *\n",
    "from PEGenerator import *\n",
    "import PEGenerator\n",
    "from models import *\n",
    "from utils import *\n",
    "from Encoders import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T07:58:58.257584Z",
     "start_time": "2024-06-11T07:58:58.059586Z"
    }
   },
   "outputs": [],
   "source": [
    "data_root_path = \"../data/Challenge/\"\n",
    "embedding_path = \"../../\"\n",
    "KG_root_path = None\n",
    "popularity_path = \"../data/Challenge/popularity\"\n",
    "config = {'title_length':30,\n",
    "              'body_length':100,\n",
    "              'max_clicked_news':50,\n",
    "              'npratio':1,\n",
    "              'news_encoder_name':\"CNN\",\n",
    "              'user_encoder_name':\"Att\",\n",
    "             'attrs':['title','body','vert'],\n",
    "             'word_filter':0,\n",
    "             'data_root_path':data_root_path,\n",
    "             'embedding_path':embedding_path,\n",
    "             'KG_root_path':KG_root_path,\n",
    "            'popularity_path':popularity_path,\n",
    "             'max_entity_num':5}\n",
    "model_config = {\n",
    "        'news_encoder':0,\n",
    "        'popularity_user_modeling':True,\n",
    "        'rel':True,\n",
    "        'ctr':True,\n",
    "        'content':True,\n",
    "        'rece_emb':True,\n",
    "        'activity':True\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T08:35:17.505202Z",
     "start_time": "2024-06-11T08:35:16.705203Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19779\n",
      "2472\n",
      "2473\n"
     ]
    }
   ],
   "source": [
    "News = NewsContent(config)\n",
    "TrainUsers = UserContent(News.news_index,config,'train.tsv',2)\n",
    "ValidUsers = UserContent(News.news_index,config,'val.tsv',1)\n",
    "TestUsers = UserContent(News.news_index,config,'test.tsv',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19779\n",
      "19916\n",
      "2473\n",
      "2472\n"
     ]
    }
   ],
   "source": [
    "train_sess,train_buckets, train_user_id, train_label = get_train_input(TrainUsers.session,News.news_index,config)\n",
    "test_impressions, test_userids = get_test_input(TestUsers.session,News.news_index)\n",
    "val_impressions, val_userids = get_test_input(ValidUsers.session,News.news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(News.news_stat_imp[train_sess[0, 0],train_buckets[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548\n"
     ]
    }
   ],
   "source": [
    "print(News.news_publish_bucket[train_sess[0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_word_embedding_matrix, have_word = load_matrix(embedding_path,News.word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EbnerdTrainData(Dataset):\n",
    "    def __init__(self, News, User, session, user_id, buckets, labels):\n",
    "        self.News = News\n",
    "        self.User = User\n",
    "        self.session = session\n",
    "        self.buckets = buckets\n",
    "        self.user_id = user_id\n",
    "        self.labels = labels\n",
    "        self.length = len(self.session)\n",
    "        # ?\n",
    "        # self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        candidates = torch.IntTensor(self.session[idx])\n",
    "        candidates_data = torch.LongTensor(self.News.fetch_news(candidates))\n",
    "        candidates_ctr = torch.FloatTensor([self.News.get_ctr(x, self.buckets[idx]) for x in candidates])\n",
    "        candidates_rece_emb_index = torch.IntTensor([self.News.news_publish_bucket2[x] for x in candidates])\n",
    "        user_activity_input = 1\n",
    "        clicked_input = torch.IntTensor(self.User.click[self.user_id[idx]])\n",
    "        clicked_input_data = torch.LongTensor(self.News.fetch_news(clicked_input))\n",
    "        # print(clicked_input)\n",
    "        clicked_ctr = torch.FloatTensor([self.News.get_ctr(self.User.click[self.user_id[idx]][i], self.User.click_bucket[self.user_id[idx]][i]) for i in range(len(clicked_input))])\n",
    "        # print(clicked_ctr)\n",
    "        input = [candidates_data,candidates_ctr,candidates_rece_emb_index,user_activity_input,clicked_input_data,clicked_ctr]\n",
    "        # for x in range(len(input)):\n",
    "        #     input[x] = torch.FloatTensor(input[x])\n",
    "        labels = torch.LongTensor(self.labels[idx])\n",
    "        return input, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EbnerdTestData(Dataset):\n",
    "    def __init__(self, News, User, user_id, impressions):\n",
    "        self.News = News\n",
    "        self.User = User\n",
    "        self.impressions = impressions\n",
    "        self.user_id = user_id\n",
    "        \n",
    "        self.length = len(self.user_id)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        candidates = self.impressions[idx]['docs']\n",
    "        candidates_ctr = [self.News.get_ctr(x, self.impressions[idx]['tsp']) for x in candidates]\n",
    "        candidates_rece_emb_index = [self.News.news_publish_bucket2[x] for x in candidates]\n",
    "        user_activity_input = 1\n",
    "        clicked_input = self.User.click[self.user_id[idx]]\n",
    "        # print(clicked_input)\n",
    "        clicked_ctr = [self.News.get_ctr(self.User.click[self.user_id[idx]][i], self.User.click_bucket[self.user_id[idx]][i]) for i in range(len(clicked_input))]\n",
    "        # print(clicked_ctr)\n",
    "        input = [candidates,candidates_ctr,candidates_rece_emb_index,user_activity_input,clicked_input,clicked_ctr]\n",
    "        for x in range(len(input)):\n",
    "            input[x] = torch.FloatTensor(input[x])\n",
    "        labels = self.impressions[idx]['labels']\n",
    "\n",
    "        return input, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = TrainGenerator(News,TrainUsers,train_sess,train_user_id,train_buckets,train_label,32)\n",
    "train_loader = DataLoader(EbnerdTrainData(News, TrainUsers, train_sess, train_user_id, train_buckets, train_label), 1)\n",
    "# # test_user_generator = UserGenerator(News,TestUsers,32)\n",
    "# test_loader = DataLoader(EbnerdTestData(News, TestUsers, test_userids, test_impressions), 32)\n",
    "# # val_user_generator = UserGenerator(News,ValidUsers,32)\n",
    "\n",
    "# val_loader = DataLoader(EbnerdTestData(News, ValidUsers, val_userids, val_impressions), 8)\n",
    "# # news_generator = NewsGenerator(News,32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex_og_samliv': 0,\n",
       " 'podcast': 1,\n",
       " 'nyheder': 2,\n",
       " 'bibliotek': 3,\n",
       " 'penge': 4,\n",
       " 'services': 5,\n",
       " 'krimi': 6,\n",
       " 'biler': 7,\n",
       " 'om_ekstra_bladet': 8,\n",
       " 'nationen': 9,\n",
       " 'haandvaerkeren': 10,\n",
       " 'musik': 11,\n",
       " 'play': 12,\n",
       " 'sport': 13,\n",
       " 'horoskoper': 14,\n",
       " 'underholdning': 15,\n",
       " 'opinionen': 16,\n",
       " 'side9': 17,\n",
       " 'forbrug': 18,\n",
       " 'incoming': 19,\n",
       " 'auto': 20,\n",
       " 'ferie': 21,\n",
       " 'dagsorden': 22,\n",
       " 'vin': 23,\n",
       " 'plus': 24}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News.category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': array([[ 6559,  7914,   213,   138, 12011,   275,   374,    64,     6,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0],\n",
      "       [ 1507,  1862,   153,   119,  2497,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0]]), 'vert': array([[ 2],\n",
      "       [13]]), 'subvert': None, 'body': array([[   113,     67,    697,    213,     64,     54,   4369,   7914,\n",
      "        120597,   6360,     13, 120598, 120599,  23690,     11,   5208,\n",
      "          2314,   3548,     21,     76,   5525,    179, 120600,  21950,\n",
      "            36,    122,     30,   1628,    337,  18535,    225, 120601,\n",
      "            21,    300,    479,     98,    595,  17715,      8,   1885,\n",
      "           225,    113, 120602,     11,      9,   8381, 120603,     36,\n",
      "           453,     64,    138,   1204,  15188,    144,     23,     36,\n",
      "            13,    492,    509,    286,   1189,     51,     23,    735,\n",
      "          3671,     21,     13,     41,     98,  12042,  12011,     21,\n",
      "          7845, 120604,     98,  70138,     13,    184,     36,      9,\n",
      "            40,     15,   2918,     61,    845,     36,    122,     15,\n",
      "           227, 120597,     51,     23,    735,   3671,     21,    119,\n",
      "           120,     48,  53274,     21],\n",
      "       [ 10135,  21317,   1754,     27,     78,   2319,  36348,     13,\n",
      "          1745,    144,   1382,     13,   1035,     36,     39,   2320,\n",
      "            52,  20820,     60,     61,   9064,     57,   1659,     21,\n",
      "            22,     29,   2607,     51,   1159,     27,   1008,     30,\n",
      "           254,     36,     78,     41,   9162,     21,   2320,    525,\n",
      "         85628,  21083,  54319,  89530,   7936,   1928,      9,   2545,\n",
      "          1041,    119,     64,   1733,   2497,     36,     39,   1507,\n",
      "            51,     76,  15890,   4550,  66926,   9064,   2314,   4545,\n",
      "            13,   2051,    127,    158,    311,   2861,     11,   1550,\n",
      "            21,    294,    142,    325,     22,   1884,     41,     30,\n",
      "          4720,     98,    529,     97,     36,    292,    518,     76,\n",
      "           144,  14093,     26,   2545,   1041,     51,  41591,     29,\n",
      "          2607,     36,    139,     98]]), 'entity': None}\n",
      "{'title': array([[     0,      0,      0, ...,      0,      0,      0],\n",
      "       [     0,      0,      0, ...,      0,      0,      0],\n",
      "       [     0,      0,      0, ...,      0,      0,      0],\n",
      "       ...,\n",
      "       [  6570,  51696,     51, ...,      0,      0,      0],\n",
      "       [   294,   4032, 125969, ...,      0,      0,      0],\n",
      "       [   609,     13,   4283, ...,      0,      0,      0]]), 'vert': array([[ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 0],\n",
      "       [ 6],\n",
      "       [ 2],\n",
      "       [15],\n",
      "       [ 6]]), 'subvert': None, 'body': array([[    0,     0,     0, ...,     0,     0,     0],\n",
      "       [    0,     0,     0, ...,     0,     0,     0],\n",
      "       [    0,     0,     0, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [ 5648,   144, 21582, ...,  6487,     8,    36],\n",
      "       [ 5273, 19404,    36, ...,    13,   386,    36],\n",
      "       [   54,  1286,    98, ...,  3394,    21,  1876]]), 'entity': None}\n",
      "tensor([[  6559,   7914,    213,    138,  12011,    275,    374,     64,      6,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,    113,     67,    697,    213,     64,     54,\n",
      "           4369,   7914, 120597,   6360,     13, 120598, 120599,  23690,     11,\n",
      "           5208,   2314,   3548,     21,     76,   5525,    179, 120600,  21950,\n",
      "             36,    122,     30,   1628,    337,  18535,    225, 120601,     21,\n",
      "            300,    479,     98,    595,  17715,      8,   1885,    225,    113,\n",
      "         120602,     11,      9,   8381, 120603,     36,    453,     64,    138,\n",
      "           1204,  15188,    144,     23,     36,     13,    492,    509,    286,\n",
      "           1189,     51,     23,    735,   3671,     21,     13,     41,     98,\n",
      "          12042,  12011,     21,   7845, 120604,     98,  70138,     13,    184,\n",
      "             36,      9,     40,     15,   2918,     61,    845,     36,    122,\n",
      "             15,    227, 120597,     51,     23,    735,   3671,     21,    119,\n",
      "            120,     48,  53274,     21,      2],\n",
      "        [  1507,   1862,    153,    119,   2497,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,  10135,  21317,   1754,     27,     78,   2319,\n",
      "          36348,     13,   1745,    144,   1382,     13,   1035,     36,     39,\n",
      "           2320,     52,  20820,     60,     61,   9064,     57,   1659,     21,\n",
      "             22,     29,   2607,     51,   1159,     27,   1008,     30,    254,\n",
      "             36,     78,     41,   9162,     21,   2320,    525,  85628,  21083,\n",
      "          54319,  89530,   7936,   1928,      9,   2545,   1041,    119,     64,\n",
      "           1733,   2497,     36,     39,   1507,     51,     76,  15890,   4550,\n",
      "          66926,   9064,   2314,   4545,     13,   2051,    127,    158,    311,\n",
      "           2861,     11,   1550,     21,    294,    142,    325,     22,   1884,\n",
      "             41,     30,   4720,     98,    529,     97,     36,    292,    518,\n",
      "             76,    144,  14093,     26,   2545,   1041,     51,  41591,     29,\n",
      "           2607,     36,    139,     98,     13]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x[0][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 400\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = \\\n",
    "create_pe_model(config, model_config, News, title_word_embedding_matrix, entity_embedding_matrix=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "torch.Size([2, 30])\n",
      "torch.Size([2, 1, 30])\n",
      "30 400\n",
      "torch.Size([2, 1, 30])\n",
      "torch.Size([2, 1, 30, 300])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [2, 1, 30, 300]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Step 5: Compute the lambda gradient values for the pairwise loss (spedup) with the compute_lambda_i method on the scores and the output labels\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(out, y)\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\RecSys-PP-Rec\\Code\\Encoders.py:860\u001b[0m, in \u001b[0;36mPE_model.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    851\u001b[0m     \u001b[38;5;66;03m# model = Model([candidates,candidates_ctr,candidates_rece_emb_index,user_activity_input,clicked_input,clicked_ctr], [logits])\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \t\u001b[38;5;66;03m# input candidates,candidates_ctr,candidates_rece_emb_index,user_activity_input,clicked_input,clicked_ctr\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;66;03m# 4 clicked input\u001b[39;00m\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# 5 clicked ctr\u001b[39;00m\n\u001b[0;32m    859\u001b[0m     time_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_embedding_layer(x[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 860\u001b[0m     candidate_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_distributed1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    861\u001b[0m     bias_candidate_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_distributed2(x[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrece_emb\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\RecSys-PP-Rec\\Code\\Encoders.py:571\u001b[0m, in \u001b[0;36mTimeDistributed.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# Squash samples and timesteps into a single axis\u001b[39;00m\n\u001b[0;32m    569\u001b[0m x_reshape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# (samples * timesteps, input_size)\u001b[39;00m\n\u001b[1;32m--> 571\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_reshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m# We have to reshape Y\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first:\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\RecSys-PP-Rec\\Code\\Encoders.py:243\u001b[0m, in \u001b[0;36mNews_encoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mprint\u001b[39m(title_input\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    242\u001b[0m     title_encoder \u001b[38;5;241m=\u001b[39m Doc_encoder(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLengthTable[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embedding_layer)\n\u001b[1;32m--> 243\u001b[0m     title_vec \u001b[38;5;241m=\u001b[39m \u001b[43mtitle_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattrs\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\RecSys-PP-Rec\\Code\\Encoders.py:98\u001b[0m, in \u001b[0;36mDoc_encoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnews_encoder\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 98\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnews_encoder\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelfAtt\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 2D (unbatched) or 3D (batched) input to conv1d, but got input of size: [2, 1, 30, 300]"
     ]
    }
   ],
   "source": [
    "# Step 2: Create your Adam optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 3: Iterate over the data for the number of epochs\n",
    "for epoch in range(1):\n",
    "\n",
    "    # Step 4: Iterate over each batch of data and compute the scores using the forward pass of the network\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "    \n",
    "        # Step 5: Compute the lambda gradient values for the pairwise loss (spedup) with the compute_lambda_i method on the scores and the output labels\n",
    "        loss = loss_fn(out, y)\n",
    "\n",
    "        # Step 6: Bacward from the scores with the use of the lambda gradient values\n",
    "        if loss is not None:\n",
    "            torch.autograd.backward(out, loss)\n",
    "            \n",
    "            # Step 7: Update the weights using the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "    # Step 8: At the end of the epoch, evaluate the model on the data using the evaluate_model function (both train and val)\n",
    "    model.eval()\n",
    "#     val_rankings = news_ranking(model_config,ctr_weight,val_predicted_activity_gates,val_user_scoring,news_scoring,\n",
    "#                                bias_candidate_score,news_bias_vecs,time_embedding_matrix,bias_content_scorer,\n",
    "#                                News,val_impressions)\n",
    "#     train_metrics = evaluate_model(data, model.forward, 'train')\n",
    "#     val_metrics = evaluate_model(data, model.forward, 'validation')\n",
    "    \n",
    "        \n",
    "#     print(f\"Epoch {epoch+1}/{params.epochs} - Train Metrics: {train_metrics}, Val Metrics: {val_metrics}\")\n",
    "\n",
    "#     # Step 9: Append the metrics to train_metrics_epoch and val_metrics_epoch\n",
    "#     train_metrics_epoch.append(train_metrics)\n",
    "#     val_metrics_epoch.append(val_metrics)\n",
    "    \n",
    "# return {\n",
    "#     \"metrics_train\": train_metrics_epoch,\n",
    "#     \"metrics_val\": val_metrics_epoch\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-11T07:59:00.558967Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.compile(loss=['categorical_crossentropy'],\n",
    "#                   optimizer=Adam(lr=0.0001), \n",
    "#                   metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-11T07:59:00.560967Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = create_pe_model(config,model_config,News,title_word_embedding_matrix,News.entity_embedding)\n",
    "    model.fit_generator(train_generator,epochs=2)\n",
    "    news_scoring = news_encoder.predict_generator(news_generator,verbose=True)\n",
    "    user_scoring = user_encoder.predict_generator(test_user_generator,verbose=True)\n",
    "    val_user_scoring = user_encoder.predict_generator(val_user_generator,verbose=True)\n",
    "\n",
    "\n",
    "    news_bias_vecs = bias_news_encoder.predict_generator(news_generator,verbose=True)\n",
    "\n",
    "    if model_config['content'] and not model_config['rece_emb']:\n",
    "        bias_candidate_score = bias_content_scorer.predict(news_bias_vecs,batch_size=32,verbose=True)\n",
    "        bias_candidate_score = bias_candidate_score[:,0]\n",
    "    else:\n",
    "        bias_candidate_score = 0\n",
    "\n",
    "    ctr_weight = scaler.get_weights()[0][0,0]\n",
    "    time_embedding_matrix = time_embedding_layer.get_weights()[0]\n",
    "    \n",
    "    predicted_activity_gates = activity_gater.predict(user_scoring,verbose=True)\n",
    "    predicted_activity_gates = predicted_activity_gates[:,0]\n",
    "    \n",
    "    val_predicted_activity_gates = activity_gater.predict(val_user_scoring,verbose=True)\n",
    "    val_predicted_activity_gates = val_predicted_activity_gates[:,0]\n",
    "    \n",
    "    rankings = news_ranking(model_config,ctr_weight,predicted_activity_gates,user_scoring,news_scoring,\n",
    "                                bias_candidate_score,news_bias_vecs,time_embedding_matrix,bias_content_scorer,\n",
    "                                News,test_impressions)\n",
    "    \n",
    "    val_rankings = news_ranking(model_config,ctr_weight,val_predicted_activity_gates,val_user_scoring,news_scoring,\n",
    "                               bias_candidate_score,news_bias_vecs,time_embedding_matrix,bias_content_scorer,\n",
    "                               News,val_impressions)\n",
    "    \n",
    "    performance = evaluate_performance(rankings,test_impressions)\n",
    "    val_performance = evaluate_performance(val_rankings,val_impressions)\n",
    "\n",
    "    cold = []\n",
    "    for TOP_COLD_NUM in [0,1,3,5,]:\n",
    "        g = evaluate_cold_users(rankings,test_impressions,TestUsers.click,TOP_COLD_NUM)\n",
    "        cold.append(g)\n",
    "    diversity = []\n",
    "    for TOP_DIVERSITY_NUM in range(1,11):\n",
    "        div_top = evaluate_diversity_topic_all(TOP_DIVERSITY_NUM,rankings,test_impressions,News,TestUsers)\n",
    "        div_ilxd = evaluate_density_ILxD(TOP_DIVERSITY_NUM,rankings,test_impressions,news_scoring)\n",
    "        diversity.append([div_top,div_ilxd])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
