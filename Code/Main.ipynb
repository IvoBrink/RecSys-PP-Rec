{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T07:58:56.802485Z",
     "start_time": "2024-06-11T07:58:50.812875Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NewsContent import *\n",
    "from UserContent import *\n",
    "from preprocessing import *\n",
    "from PEGenerator import *\n",
    "import PEGenerator\n",
    "from models import *\n",
    "from utils import *\n",
    "from Encoders import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T07:58:58.257584Z",
     "start_time": "2024-06-11T07:58:58.059586Z"
    }
   },
   "outputs": [],
   "source": [
    "data_root_path = \"../data/Challenge/\"\n",
    "embedding_path = None\n",
    "KG_root_path = None\n",
    "popularity_path = \"../data/Challenge/popularity\"\n",
    "config = {'title_length':30,\n",
    "              'body_length':100,\n",
    "              'max_clicked_news':50,\n",
    "              'npratio':1,\n",
    "              'news_encoder_name':\"CNN\",\n",
    "              'user_encoder_name':\"Att\",\n",
    "             'attrs':['title','vert','entity'],\n",
    "             'word_filter':0,\n",
    "             'data_root_path':data_root_path,\n",
    "             'embedding_path':embedding_path,\n",
    "             'KG_root_path':KG_root_path,\n",
    "            'popularity_path':popularity_path,\n",
    "             'max_entity_num':5}\n",
    "model_config = {\n",
    "        'news_encoder':1,\n",
    "        'popularity_user_modeling':True,\n",
    "        'rel':True,\n",
    "        'ctr':True,\n",
    "        'content':True,\n",
    "        'rece_emb':True,\n",
    "        'activity':True\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T08:35:17.505202Z",
     "start_time": "2024-06-11T08:35:16.705203Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19779\n",
      "2472\n",
      "2473\n"
     ]
    }
   ],
   "source": [
    "News = NewsContent(config)\n",
    "TrainUsers = UserContent(News.news_index,config,'train.tsv',2)\n",
    "ValidUsers = UserContent(News.news_index,config,'val.tsv',1)\n",
    "TestUsers = UserContent(News.news_index,config,'test.tsv',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19779\n",
      "19916\n",
      "2473\n",
      "2472\n"
     ]
    }
   ],
   "source": [
    "train_sess,train_buckets, train_user_id, train_label = get_train_input(TrainUsers.session,News.news_index,config)\n",
    "test_impressions, test_userids = get_test_input(TestUsers.session,News.news_index)\n",
    "val_impressions, val_userids = get_test_input(ValidUsers.session,News.news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 19776 19777 19778]\n"
     ]
    }
   ],
   "source": [
    "print(train_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m title_word_embedding_matrix, have_word \u001b[38;5;241m=\u001b[39m \u001b[43mload_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNews\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/RecSys-PP-Rec-1/Code/preprocessing.py:77\u001b[0m, in \u001b[0;36mload_matrix\u001b[0;34m(embedding_path, word_dict)\u001b[0m\n\u001b[1;32m     75\u001b[0m embedding_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(word_dict)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m300\u001b[39m))\n\u001b[1;32m     76\u001b[0m have_word\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglove.840B.300d.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         l\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mreadline()\n",
      "File \u001b[0;32m<frozen posixpath>:76\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "title_word_embedding_matrix, have_word = load_matrix(embedding_path,News.word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24888.0\n"
     ]
    }
   ],
   "source": [
    "# train_generator = TrainGenerator(News,TrainUsers,train_sess,train_user_id,train_buckets,train_label,32)\n",
    "# test_user_generator = UserGenerator(News,TestUsers,32)\n",
    "# val_user_generator = UserGenerator(News,ValidUsers,32)\n",
    "# news_generator = NewsGenerator(News,32)\n",
    "\n",
    "\n",
    "print(sum(sum(News.news_stat_click)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EbnerdDataSet(Dataset):\n",
    "    def __init__(self, News, User, session, user_id, buckets, labels, batch_size):\n",
    "        self.News = News\n",
    "        self.User = User\n",
    "        self.session = session\n",
    "        self.user_id = user_id\n",
    "        self.buckets = buckets\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.length = len(self.session)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        candidates = self.session[idx]\n",
    "        candidates_ctr = News.load_ctr(candidates)\n",
    "        candidates_rece_emb_index = ...\n",
    "        user_activity_input = ...\n",
    "        clicked_input = TrainUsers.click[self.user_id[idx]]\n",
    "        clicked_ctr = NewsContent.load_ctr(self.clicked_input)\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        input = [candidates,candidates_ctr,candidates_rece_emb_index,user_activity_input,clicked_input,clicked_ctr]\n",
    "        \n",
    "        # batch_user_id = self.user_id[idx]\n",
    "        # batch_buckets = self.buckets[idx]\n",
    "        # batch_label = self.labels[idx]\n",
    "        # batch_user = self.User.get_user(batch_user_id)\n",
    "        # batch_news = self.News.get_news(batch_buckets)\n",
    "        \n",
    "        return input, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'UserContent' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = \\\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# create_pe_model(News, config, model_config, title_word_embedding_matrix, entity_embedding_matrix=None)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTrainUsers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataloader.py:349\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 349\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    351\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/sampler.py:139\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/sampler.py:146\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnum_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# dataset size might change at runtime\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'UserContent' has no len()"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = \\\n",
    "# create_pe_model(News, config, model_config, title_word_embedding_matrix, entity_embedding_matrix=None)\n",
    "\n",
    "train_loader = DataLoader(TrainUsers, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "for x, y in train_loader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Adam'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mAdam\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m      4\u001b[0m create_pe_model(News, config, model_config, title_word_embedding_matrix, entity_embedding_matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(TrainUsers, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Adam'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 2: Create your Adam optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 3: Iterate over the data for the number of epochs\n",
    "for epoch in range(1):\n",
    "\n",
    "    # Step 4: Iterate over each batch of data and compute the scores using the forward pass of the network\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "    \n",
    "        # Step 5: Compute the lambda gradient values for the pairwise loss (spedup) with the compute_lambda_i method on the scores and the output labels\n",
    "        loss = loss_fn(out, y)\n",
    "\n",
    "        # Step 6: Bacward from the scores with the use of the lambda gradient values\n",
    "        if loss is not None:\n",
    "            torch.autograd.backward(out, loss)\n",
    "            \n",
    "            # Step 7: Update the weights using the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "    # Step 8: At the end of the epoch, evaluate the model on the data using the evaluate_model function (both train and val)\n",
    "    model.eval()\n",
    "    train_metrics = evaluate_model(data, model.forward, 'train')\n",
    "    val_metrics = evaluate_model(data, model.forward, 'validation')\n",
    "    \n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{params.epochs} - Train Metrics: {train_metrics}, Val Metrics: {val_metrics}\")\n",
    "\n",
    "    # Step 9: Append the metrics to train_metrics_epoch and val_metrics_epoch\n",
    "    train_metrics_epoch.append(train_metrics)\n",
    "    val_metrics_epoch.append(val_metrics)\n",
    "    \n",
    "return {\n",
    "    \"metrics_train\": train_metrics_epoch,\n",
    "    \"metrics_val\": val_metrics_epoch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-11T07:59:00.558967Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.compile(loss=['categorical_crossentropy'],\n",
    "#                   optimizer=Adam(lr=0.0001), \n",
    "#                   metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-11T07:59:00.560967Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "\n",
    "    model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = create_pe_model(config,model_config,News,title_word_embedding_matrix,News.entity_embedding)\n",
    "    model.fit_generator(train_generator,epochs=2)\n",
    "    news_scoring = news_encoder.predict_generator(news_generator,verbose=True)\n",
    "    user_scoring = user_encoder.predict_generator(test_user_generator,verbose=True)\n",
    "    val_user_scoring = user_encoder.predict_generator(val_user_generator,verbose=True)\n",
    "\n",
    "\n",
    "    news_bias_vecs = bias_news_encoder.predict_generator(news_generator,verbose=True)\n",
    "\n",
    "    if model_config['content'] and not model_config['rece_emb']:\n",
    "        bias_candidate_score = bias_content_scorer.predict(news_bias_vecs,batch_size=32,verbose=True)\n",
    "        bias_candidate_score = bias_candidate_score[:,0]\n",
    "    else:\n",
    "        bias_candidate_score = 0\n",
    "\n",
    "    ctr_weight = scaler.get_weights()[0][0,0]\n",
    "    time_embedding_matrix = time_embedding_layer.get_weights()[0]\n",
    "    \n",
    "    predicted_activity_gates = activity_gater.predict(user_scoring,verbose=True)\n",
    "    predicted_activity_gates = predicted_activity_gates[:,0]\n",
    "    \n",
    "    val_predicted_activity_gates = activity_gater.predict(val_user_scoring,verbose=True)\n",
    "    val_predicted_activity_gates = val_predicted_activity_gates[:,0]\n",
    "    \n",
    "    rankings = news_ranking(model_config,ctr_weight,predicted_activity_gates,user_scoring,news_scoring,\n",
    "                                bias_candidate_score,news_bias_vecs,time_embedding_matrix,bias_content_scorer,\n",
    "                                News,test_impressions)\n",
    "    \n",
    "    val_rankings = news_ranking(model_config,ctr_weight,val_predicted_activity_gates,val_user_scoring,news_scoring,\n",
    "                               bias_candidate_score,news_bias_vecs,time_embedding_matrix,bias_content_scorer,\n",
    "                               News,val_impressions)\n",
    "    \n",
    "    performance = evaluate_performance(rankings,test_impressions)\n",
    "    val_performance = evaluate_performance(val_rankings,val_impressions)\n",
    "\n",
    "    cold = []\n",
    "    for TOP_COLD_NUM in [0,1,3,5,]:\n",
    "        g = evaluate_cold_users(rankings,test_impressions,TestUsers.click,TOP_COLD_NUM)\n",
    "        cold.append(g)\n",
    "    diversity = []\n",
    "    for TOP_DIVERSITY_NUM in range(1,11):\n",
    "        div_top = evaluate_diversity_topic_all(TOP_DIVERSITY_NUM,rankings,test_impressions,News,TestUsers)\n",
    "        div_ilxd = evaluate_density_ILxD(TOP_DIVERSITY_NUM,rankings,test_impressions,news_scoring)\n",
    "        diversity.append([div_top,div_ilxd])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
