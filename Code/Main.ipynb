{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:44:51.052648Z",
     "start_time": "2024-06-23T20:44:43.498034Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NewsContent import *\n",
    "from UserContent import *\n",
    "from preprocessing import *\n",
    "from PEGenerator import *\n",
    "import PEGenerator\n",
    "from models import *\n",
    "from utils import *\n",
    "from Encoders import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T20:44:51.286650Z",
     "start_time": "2024-06-23T20:44:51.054656Z"
    }
   },
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:44:51.475649Z",
     "start_time": "2024-06-23T20:44:51.288661Z"
    }
   },
   "outputs": [],
   "source": [
    "data_root_path = \"../data/Challenge/\"\n",
    "embedding_path = \"../../\"\n",
    "KG_root_path = \"../data/Challenge/entity\"\n",
    "popularity_path = \"../data/Challenge/popularity\"\n",
    "config = {'title_length':30,\n",
    "              'body_length':100,\n",
    "              'max_clicked_news':50,\n",
    "              'npratio':1,\n",
    "              'news_encoder_name':\"CNN\",\n",
    "              'user_encoder_name':\"Att\",\n",
    "             'attrs':['title', 'entity','vert'],\n",
    "             'word_filter':0,\n",
    "             'data_root_path':data_root_path,\n",
    "             'embedding_path':embedding_path,\n",
    "             'KG_root_path':KG_root_path,\n",
    "            'popularity_path':popularity_path,\n",
    "            'batch_size': 32,\n",
    "             'max_entity_num':5}\n",
    "model_config = {\n",
    "        'news_encoder':0,\n",
    "        'popularity_user_modeling':True,\n",
    "        'rel':True,\n",
    "        'ctr':True,\n",
    "        'content':True,\n",
    "        'rece_emb':True,\n",
    "        'activity':True\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-06-23T20:45:10.721551Z",
     "start_time": "2024-06-23T20:44:51.477650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19779\n",
      "2472\n",
      "2473\n"
     ]
    }
   ],
   "source": [
    "News = NewsContent(config)\n",
    "\n",
    "TrainUsers = UserContent(News.news_index,config,'train.tsv',2)\n",
    "ValidUsers = UserContent(News.news_index,config,'val.tsv',1)\n",
    "TestUsers = UserContent(News.news_index,config,'test.tsv',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:45:11.050558Z",
     "start_time": "2024-06-23T20:45:10.724553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19779\n",
      "19916\n",
      "2473\n",
      "2472\n"
     ]
    }
   ],
   "source": [
    "train_sess,train_buckets, train_user_id, train_label = get_train_input(TrainUsers.session,News.news_index,config)\n",
    "test_impressions, test_userids = get_test_input(TestUsers.session,News.news_index)\n",
    "val_impressions, val_userids = get_test_input(ValidUsers.session,News.news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:18.998182Z",
     "start_time": "2024-06-23T20:45:11.052559Z"
    }
   },
   "outputs": [],
   "source": [
    "title_word_embedding_matrix, have_word = load_matrix(embedding_path,News.word_dict)\n",
    "entity_embedding_matrix, have_word2 = load_matrix(embedding_path, News.entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:19.268181Z",
     "start_time": "2024-06-23T20:46:18.999184Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TrainDataset(News, TrainUsers, train_sess, train_user_id, train_buckets, train_label), config['batch_size'])\n",
    "test_user_data = UserDataset(News,TestUsers), config['batch_size']\n",
    "val_user_data = UserDataset(News,ValidUsers)\n",
    "news_data = NewsDataset(News)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:19.520202Z",
     "start_time": "2024-06-23T20:46:19.270188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(type(x[1]))\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:20.073213Z",
     "start_time": "2024-06-23T20:46:19.522203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved news_encoder to cuda\n",
      "Moved bias_news_encoder to cuda\n",
      "Moved pop_aware_user_encoder to cuda\n",
      "Moved bias_scorer to cuda\n",
      "Moved activity_gater to cuda\n",
      "Moved time_embedding_layer to cuda\n",
      "Moved time_distributed1 to cuda\n",
      "Moved time_distributed2 to cuda\n",
      "Moved time_distributed3 to cuda\n",
      "Moved scaler to cuda\n",
      "Moved softmax to cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = \\\n",
    "create_pe_model(config, model_config, News, title_word_embedding_matrix, entity_embedding_matrix, device)\n",
    "\n",
    "model.to(device)\n",
    "for name, module in model.named_children():\n",
    "    module.to(device)\n",
    "    print(f'Moved {name} to {device}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_encoder.word_embedding_layer.weight: cuda:0\n",
      "news_encoder.entity_embedding_layer.weight: cuda:0\n",
      "news_encoder.attention.WQ.weight: cuda:0\n",
      "news_encoder.attention.WK.weight: cuda:0\n",
      "news_encoder.attention.WV.weight: cuda:0\n",
      "news_encoder.attentive_pool.dense_tanh.weight: cuda:0\n",
      "news_encoder.attentive_pool.dense_tanh.bias: cuda:0\n",
      "news_encoder.attentive_pool.dense_flat.weight: cuda:0\n",
      "news_encoder.attentive_pool.dense_flat.bias: cuda:0\n",
      "news_encoder.title_encoder.conv.weight: cuda:0\n",
      "news_encoder.title_encoder.conv.bias: cuda:0\n",
      "news_encoder.title_encoder.attentivePool.dense_tanh.weight: cuda:0\n",
      "news_encoder.title_encoder.attentivePool.dense_tanh.bias: cuda:0\n",
      "news_encoder.title_encoder.attentivePool.dense_flat.weight: cuda:0\n",
      "news_encoder.title_encoder.attentivePool.dense_flat.bias: cuda:0\n",
      "news_encoder.vert_encoder.embedding_layer.weight: cuda:0\n",
      "bias_news_encoder.word_embedding_layer.weight: cuda:0\n",
      "bias_news_encoder.entity_embedding_layer.weight: cuda:0\n",
      "bias_news_encoder.attention.WQ.weight: cuda:0\n",
      "bias_news_encoder.attention.WK.weight: cuda:0\n",
      "bias_news_encoder.attention.WV.weight: cuda:0\n",
      "bias_news_encoder.attentive_pool.dense_tanh.weight: cuda:0\n",
      "bias_news_encoder.attentive_pool.dense_tanh.bias: cuda:0\n",
      "bias_news_encoder.attentive_pool.dense_flat.weight: cuda:0\n",
      "bias_news_encoder.attentive_pool.dense_flat.bias: cuda:0\n",
      "bias_news_encoder.title_encoder.conv.weight: cuda:0\n",
      "bias_news_encoder.title_encoder.conv.bias: cuda:0\n",
      "bias_news_encoder.title_encoder.attentivePool.dense_tanh.weight: cuda:0\n",
      "bias_news_encoder.title_encoder.attentivePool.dense_tanh.bias: cuda:0\n",
      "bias_news_encoder.title_encoder.attentivePool.dense_flat.weight: cuda:0\n",
      "bias_news_encoder.title_encoder.attentivePool.dense_flat.bias: cuda:0\n",
      "bias_news_encoder.vert_encoder.embedding_layer.weight: cuda:0\n",
      "pop_aware_user_encoder.popularity_embedding_layer.weight: cuda:0\n",
      "pop_aware_user_encoder.MHSA.WQ.weight: cuda:0\n",
      "pop_aware_user_encoder.MHSA.WK.weight: cuda:0\n",
      "pop_aware_user_encoder.MHSA.WV.weight: cuda:0\n",
      "pop_aware_user_encoder.attentivePoolQKY.dense_tanh.weight: cuda:0\n",
      "pop_aware_user_encoder.attentivePoolQKY.dense_tanh.bias: cuda:0\n",
      "pop_aware_user_encoder.attentivePoolQKY.dense_flat.weight: cuda:0\n",
      "pop_aware_user_encoder.attentivePoolQKY.dense_flat.bias: cuda:0\n",
      "pop_aware_user_encoder.attentivePool.dense_tanh.weight: cuda:0\n",
      "pop_aware_user_encoder.attentivePool.dense_tanh.bias: cuda:0\n",
      "pop_aware_user_encoder.attentivePool.dense_flat.weight: cuda:0\n",
      "pop_aware_user_encoder.attentivePool.dense_flat.bias: cuda:0\n",
      "bias_scorer.fc1_1.weight: cuda:0\n",
      "bias_scorer.fc1_1.bias: cuda:0\n",
      "bias_scorer.fc1_2.weight: cuda:0\n",
      "bias_scorer.fc1_2.bias: cuda:0\n",
      "bias_scorer.fc1_3.weight: cuda:0\n",
      "bias_scorer.fc1_3.bias: cuda:0\n",
      "bias_scorer.fc1_4.weight: cuda:0\n",
      "bias_scorer.fc2_1.weight: cuda:0\n",
      "bias_scorer.fc2_1.bias: cuda:0\n",
      "bias_scorer.fc2_2.weight: cuda:0\n",
      "bias_scorer.fc2_2.bias: cuda:0\n",
      "bias_scorer.fc2_3.weight: cuda:0\n",
      "bias_scorer.fc3_1.weight: cuda:0\n",
      "bias_scorer.fc3_1.bias: cuda:0\n",
      "bias_scorer.fc3_2.weight: cuda:0\n",
      "bias_scorer.fc3_2.bias: cuda:0\n",
      "bias_scorer.fc3_3.weight: cuda:0\n",
      "bias_scorer.fc3_3.bias: cuda:0\n",
      "activity_gater.fc1.weight: cuda:0\n",
      "activity_gater.fc1.bias: cuda:0\n",
      "activity_gater.fc2.weight: cuda:0\n",
      "activity_gater.fc2.bias: cuda:0\n",
      "activity_gater.fc3.weight: cuda:0\n",
      "activity_gater.fc3.bias: cuda:0\n",
      "time_embedding_layer.weight: cuda:0\n",
      "scaler.scaler: cuda:0\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'{name}: {param.device}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:20.264215Z",
     "start_time": "2024-06-23T20:46:20.075214Z"
    }
   },
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:47:51.941698Z",
     "start_time": "2024-06-23T20:46:20.266217Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 623/623 [00:59<00:00, 10.43it/s]\n",
      "  0%|          | 0/2472 [00:00<?, ?it/s]C:\\Users\\ivvbr\\OneDrive - Nimble Institute\\Desktop\\MSc AI\\Recommender Systems\\RecSys-PP-Rec\\RecSys-PP-Rec\\Code\\PEGenerator.py:266: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  user_feature = torch.IntTensor([self.News.fetch_news(clicked_ids)])\n",
      "100%|██████████| 2472/2472 [00:30<00:00, 82.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, metrics: [0.6845547538907755, 0.46860510251619875, 0.5237957357439255, 0.5747252782663749]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "val_metrics_epoch = []\n",
    "num_epochs = 1\n",
    "# Step 2: Create your Adam optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 3: Iterate over the data for the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "# Step 4: Iterate over each batch of data and compute the scores using the forward pass of the network\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x= [i.to(device) for i in x]\n",
    "        y = y.to(device)\n",
    "        out = model(x)\n",
    "    \n",
    "        # Step 5: Compute the lambda gradient values for the pairwise loss (spedup) with the compute_lambda_i method on the scores and the output labels\n",
    "        loss = loss_fn(out, y)\n",
    "\n",
    "        # Step 6: Bacward from the scores with the use of the lambda gradient values\n",
    "        if loss is not None:\n",
    "            # torch.autograd.backward(out, loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Step 7: Update the weights using the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_metrics = eval_model(model_config, News, user_encoder, val_impressions, val_user_data, val_userids,\n",
    "               news_encoder, bias_news_encoder, activity_gater, time_embedding_layer, \n",
    "               bias_content_scorer, scaler, device)\n",
    "    \n",
    "    print(\"epoch: {}, metrics: {}\".format(epoch, val_metrics))\n",
    "    val_metrics_epoch.append(val_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T20:44:33.872428Z"
    }
   },
   "outputs": [],
   "source": [
    "test_metrics = eval_model(model_config, News, user_encoder, test_impressions, test_user_data, test_userids,\n",
    "               news_encoder, bias_news_encoder, activity_gater, time_embedding_layer, \n",
    "               bias_content_scorer, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:06:35.570838Z",
     "start_time": "2024-06-23T20:06:35.569842Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "model.eval()\n",
    "rankings = []\n",
    "AUC = []\n",
    "MRR = []\n",
    "nDCG5 = []\n",
    "nDCG10 =[]\n",
    "for i in trange(len(val_impressions)):\n",
    "    docids = val_impressions[i]['docs']\n",
    "    docids = np.array(docids)\n",
    "    bucket = val_impressions[i]['tsp']\n",
    "    \n",
    "    publish_time = News.news_publish_bucket2[docids]\n",
    "\n",
    "    if model_config['rel']:        \n",
    "        uv = user_encoder(val_user_data.__getitem__(val_userids[i]))\n",
    "        nv = news_encoder(torch.IntTensor(News.fetch_news(docids)))\n",
    "        rel_score = torch.matmul(nv, uv[0])\n",
    "        predicted_activity_gate = activity_gater(uv)\n",
    "        predicted_activity_gate = predicted_activity_gate[:,0]\n",
    "\n",
    "    else:\n",
    "        rel_score = 0\n",
    "    \n",
    "    if model_config['content'] and model_config['rece_emb']:\n",
    "        bias_vecs = bias_news_encoder(torch.IntTensor(News.fetch_news(docids)))\n",
    "        publish_time = bucket - publish_time\n",
    "        arg = publish_time < 0\n",
    "        publish_time[arg] = 0\n",
    "        publish_bucket = compute_Q_publish(publish_time)\n",
    "        time_emb = time_embedding_layer.weight[publish_bucket]\n",
    "        bias_vecs = torch.cat([bias_vecs,time_emb], axis=-1)\n",
    "        bias_score = bias_content_scorer(bias_vecs)\n",
    "        bias_score = bias_score[:,0]\n",
    "    else:\n",
    "        bias_score = 0\n",
    "\n",
    "\n",
    "    if model_config['activity']:\n",
    "        gate = predicted_activity_gate\n",
    "    else:\n",
    "        gate = 0.5\n",
    "    \n",
    "    if model_config['ctr']:\n",
    "        ctr = torch.FloatTensor(fetch_ctr_dim1(News,docids,bucket,FLAG_CTR))\n",
    "    else:\n",
    "        ctr = 0\n",
    "\n",
    "    score = gate*rel_score + (1-gate)*(ctr*scaler.scaler[0] + bias_score)\n",
    "    score = score.detach().numpy()\n",
    "    # print(score)\n",
    "\n",
    "    labels = val_impressions[i]['labels']\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    auc = my_auc(labels,score)\n",
    "    mrr = mrr_score(labels,score)\n",
    "    ndcg5 = ndcg_score(labels,score,k=5)\n",
    "    ndcg10 = ndcg_score(labels,score,k=10)\n",
    "\n",
    "    # print(auc, mrr, ndcg5, ndcg10)\n",
    "\n",
    "    AUC.append(auc)\n",
    "    MRR.append(mrr)\n",
    "    nDCG5.append(ndcg5)\n",
    "    nDCG10.append(ndcg10)\n",
    "    # return AUC, MRR, nDCG5, nDCG10\n",
    "\n",
    "    # rankings.append(score)\n",
    "    \n",
    "\n",
    "AUC = np.array(AUC)\n",
    "MRR = np.array(MRR)\n",
    "nDCG5 = np.array(nDCG5)\n",
    "nDCG10 = np.array(nDCG10)\n",
    "\n",
    "AUC = AUC.mean()\n",
    "MRR = MRR.mean()\n",
    "nDCG5 = nDCG5.mean()\n",
    "nDCG10 = nDCG10.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T17:19:12.894550Z"
    }
   },
   "outputs": [],
   "source": [
    "cold = []\n",
    "for TOP_COLD_NUM in [0,1,3,5,]:\n",
    "    g = evaluate_cold_users(rankings,test_impressions,TestUsers.click,TOP_COLD_NUM)\n",
    "    cold.append(g)\n",
    "diversity = []\n",
    "for TOP_DIVERSITY_NUM in range(1,11):\n",
    "    div_top = evaluate_diversity_topic_all(TOP_DIVERSITY_NUM,rankings,test_impressions,News,TestUsers)\n",
    "    div_ilxd = evaluate_density_ILxD(TOP_DIVERSITY_NUM,rankings,test_impressions,news_scoring)\n",
    "    diversity.append([div_top,div_ilxd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"val metrics\", val_metrics_epoch)\n",
    "print(\"test metrics\", performance)\n",
    "print(\"cold\", cold)\n",
    "print(\"diversity\", diversity)\n",
    "\n",
    "results = {\"val metrics\": val_metrics_epoch, \n",
    "           \"test metrics\": performance,\n",
    "           \"cold\": cold,\n",
    "           \"diversity\": diversity}\n",
    "\n",
    "import json\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished\n",
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-11T07:59:00.558967Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.compile(loss=['categorical_crossentropy'],\n",
    "#                   optimizer=Adam(lr=0.0001), \n",
    "#                   metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-11T07:59:00.560967Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NewsContent' object has no attribute 'entity_embedding'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m----> 3\u001B[0m     model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater \u001B[38;5;241m=\u001B[39m create_pe_model(config,model_config,News,title_word_embedding_matrix,\u001B[43mNews\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentity_embedding\u001B[49m)\n\u001B[0;32m      4\u001B[0m     model\u001B[38;5;241m.\u001B[39mfit_generator(train_generator,epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      5\u001B[0m     news_scoring \u001B[38;5;241m=\u001B[39m news_encoder\u001B[38;5;241m.\u001B[39mpredict_generator(news_generator,verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NewsContent' object has no attribute 'entity_embedding'"
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "\n",
    "#     model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = create_pe_model(config,model_config,News,title_word_embedding_matrix,News.entity_embedding)\n",
    "#     model.fit_generator(train_generator,epochs=2)\n",
    "#     news_scoring = news_encoder.predict_generator(news_generator,verbose=True)\n",
    "#     user_scoring = user_encoder.predict_generator(test_user_generator,verbose=True)\n",
    "#     val_user_scoring = user_encoder.predict_generator(val_user_generator,verbose=True)\n",
    "\n",
    "\n",
    "#     news_bias_vecs = bias_news_encoder.predict_generator(news_generator,verbose=True)\n",
    "\n",
    "#     if model_config['content'] and not model_config['rece_emb']:\n",
    "#         bias_candidate_score = bias_content_scorer.predict(news_bias_vecs,batch_size=32,verbose=True)\n",
    "#         bias_candidate_score = bias_candidate_score[:,0]\n",
    "#     else:\n",
    "#         bias_candidate_score = 0\n",
    "\n",
    "#     ctr_weight = scaler.get_weights()[0][0,0]\n",
    "#     time_embedding_matrix = time_embedding_layer.get_weights()[0]\n",
    "    \n",
    "#     predicted_activity_gates = activity_gater.predict(user_scoring,verbose=True)\n",
    "#     predicted_activity_gates = predicted_activity_gates[:,0]\n",
    "    \n",
    "#     val_predicted_activity_gates = activity_gater.predict(val_user_scoring,verbose=True)\n",
    "#     val_predicted_activity_gates = val_predicted_activity_gates[:,0]\n",
    "    \n",
    "#     rankings = news_ranking(model_config,ctr_weight,predicted_activity_gates,user_scoring,news_scoring,\n",
    "#                                 bias_candidate_score,news_bias_vecs,time_embedding_matrix,bias_content_scorer,\n",
    "#                                 News,test_impressions)\n",
    "    \n",
    "#     val_rankings = news_ranking(model_config,ctr_weight,val_predicted_activity_gates,val_user_scoring,news_scoring,\n",
    "#                                bias_candidate_score,news_bias_vecs,time_embedding_matrix,bias_content_scorer,\n",
    "#                                News,val_impressions)\n",
    "    \n",
    "#     performance = evaluate_performance(rankings,test_impressions)\n",
    "#     val_performance = evaluate_performance(val_rankings,val_impressions)\n",
    "\n",
    "#     cold = []\n",
    "#     for TOP_COLD_NUM in [0,1,3,5,]:\n",
    "#         g = evaluate_cold_users(rankings,test_impressions,TestUsers.click,TOP_COLD_NUM)\n",
    "#         cold.append(g)\n",
    "#     diversity = []\n",
    "#     for TOP_DIVERSITY_NUM in range(1,11):\n",
    "#         div_top = evaluate_diversity_topic_all(TOP_DIVERSITY_NUM,rankings,test_impressions,News,TestUsers)\n",
    "#         div_ilxd = evaluate_density_ILxD(TOP_DIVERSITY_NUM,rankings,test_impressions,news_scoring)\n",
    "#         diversity.append([div_top,div_ilxd])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
