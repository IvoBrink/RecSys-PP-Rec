{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:44:51.052648Z",
     "start_time": "2024-06-23T20:44:43.498034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NewsContent import *\n",
    "from UserContent import *\n",
    "from preprocessing import *\n",
    "from PEGenerator import *\n",
    "import PEGenerator\n",
    "from models import *\n",
    "from utils import *\n",
    "from Encoders import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:44:51.286650Z",
     "start_time": "2024-06-23T20:44:51.054656Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:44:51.475649Z",
     "start_time": "2024-06-23T20:44:51.288661Z"
    }
   },
   "outputs": [],
   "source": [
    "data_root_path = \"../data/Challenge/\"\n",
    "embedding_path = \"../../\"\n",
    "KG_root_path = \"../data/Challenge/entity\"\n",
    "popularity_path = \"../data/Challenge/popularity\"\n",
    "config = {'title_length':30,\n",
    "              'body_length':100,\n",
    "              'max_clicked_news':50,\n",
    "              'npratio':1,\n",
    "              'news_encoder_name':\"CNN\",\n",
    "              'user_encoder_name':\"Att\",\n",
    "             'attrs':['title', 'entity', 'vert', 'image'],\n",
    "             'word_filter':0,\n",
    "             'data_root_path':data_root_path,\n",
    "             'embedding_path':embedding_path,\n",
    "             'KG_root_path':KG_root_path,\n",
    "            'popularity_path':popularity_path,\n",
    "            'batch_size': 32,\n",
    "             'max_entity_num':5,\n",
    "             'image_emb_len': 1024}\n",
    "model_config = {\n",
    "        'news_encoder':1,\n",
    "        'popularity_user_modeling':True,\n",
    "        'rel':True,\n",
    "        'ctr':True,\n",
    "        'content':True,\n",
    "        'rece_emb':True,\n",
    "        'activity':True\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:45:10.721551Z",
     "start_time": "2024-06-23T20:44:51.477650Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24724\n",
      "12678\n",
      "12678\n"
     ]
    }
   ],
   "source": [
    "News = NewsContent(config)\n",
    "\n",
    "TrainUsers = UserContent(News.news_index,config,'train.tsv',2)\n",
    "ValidUsers = UserContent(News.news_index,config,'val.tsv',1)\n",
    "TestUsers = UserContent(News.news_index,config,'test.tsv',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   7,    8,    9,   10,   11,   12,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0, 6594,    0,    0,\n",
       "          0,    0,   20,    2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "News.fetch_news(np.array([2]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:45:11.050558Z",
     "start_time": "2024-06-23T20:45:10.724553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24724\n",
      "24888\n",
      "12678\n",
      "12678\n"
     ]
    }
   ],
   "source": [
    "train_sess,train_buckets, train_user_id, train_label = get_train_input(TrainUsers.session,News.news_index,config)\n",
    "test_impressions, test_userids = get_test_input(TestUsers.session,News.news_index)\n",
    "val_impressions, val_userids = get_test_input(ValidUsers.session,News.news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:18.998182Z",
     "start_time": "2024-06-23T20:45:11.052559Z"
    }
   },
   "outputs": [],
   "source": [
    "title_word_embedding_matrix, have_word = load_matrix(embedding_path,News.word_dict)\n",
    "entity_embedding_matrix, have_word2 = load_matrix(embedding_path, News.entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:19.268181Z",
     "start_time": "2024-06-23T20:46:18.999184Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TrainDataset(News, TrainUsers, train_sess, train_user_id, train_buckets, train_label), config['batch_size'])\n",
    "val_user_data = UserDataset(News,ValidUsers)\n",
    "test_user_data = UserDataset(News,TestUsers)\n",
    "news_data = NewsDataset(News)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['data_root_path']+'image_embeddings.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "    image_emb_matrix = np.zeros((len(News.news_index)+1, len(data.popitem()[1]),),dtype='float32')\n",
    "\n",
    "    for key in data:\n",
    "\n",
    "        if key in News.news_index:\n",
    "            image_emb_matrix[News.news_index[key]] = data[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:20.073213Z",
     "start_time": "2024-06-23T20:46:19.522203Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved news_encoder to cuda\n",
      "Moved bias_news_encoder to cuda\n",
      "Moved pop_aware_user_encoder to cuda\n",
      "Moved bias_scorer to cuda\n",
      "Moved activity_gater to cuda\n",
      "Moved time_embedding_layer to cuda\n",
      "Moved time_distributed1 to cuda\n",
      "Moved time_distributed2 to cuda\n",
      "Moved time_distributed3 to cuda\n",
      "Moved scaler to cuda\n",
      "Moved softmax to cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = \\\n",
    "create_pe_model(config, model_config, News, title_word_embedding_matrix, entity_embedding_matrix, image_emb_matrix, device)\n",
    "\n",
    "model.to(device)\n",
    "for name, module in model.named_children():\n",
    "    module.to(device)\n",
    "    print(f'Moved {name} to {device}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "colds = [5, 7, 10, 15]\n",
    "topKs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:47:51.941698Z",
     "start_time": "2024-06-23T20:46:20.266217Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 778/778 [12:01<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 0, 7: 1, 10: 2, 15: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12678/12678 [08:31<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, metrics: ([0.6926089064229985, 0.47144926379603536, 0.52643498068963, 0.5738666221515027], [[0.7247207442879775, 0.6739280855097456, 0.7121532788199455, 0.8742822128851542], [0.44844847544544264, 0.4076207803380292, 0.48691832858499523, 0.6458333333333333], [0.5142870288222771, 0.4556552139132285, 0.5905317135677942, 0.7365986575892967], [0.5418067053367344, 0.4945600973085688, 0.6037245723495729, 0.7365986575892967]], [0.00898102114991433, 0.01554145991765404, 0.020851976771516425, 0.0260843977892926, 0.030223477101861813, 0.03354274440377478, 0.036276098666792184, 0.03744753620808535, 0.03932183627415443, 0.04072756132370623], [-7.841974087817602e-09, 0.30704171685958853, 0.405508063784118, 0.4521710124183555, 0.4786200448623834, 0.49182987390848565, 0.49931879287300884, 0.5037569523158557, 0.506499656932853, 0.5080604210512404], [0.9999999921580259, 0.6140834425860614, 0.4832093457653613, 0.41906473958768725, 0.38409840499288483, 0.36444446602479236, 0.35339260694402913, 0.3465508090305411, 0.3419718578408467, 0.33883443059398843])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 738/778 [11:52<00:38,  1.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m x\u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[0;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Step 5: Compute the lambda gradient values for the pairwise loss (spedup) with the compute_lambda_i method on the scores and the output labels\u001b[39;00m\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(out, y)\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\RecSys-PP-Rec\\Code\\Encoders.py:918\u001b[0m, in \u001b[0;36mPE_model.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    915\u001b[0m bias_candidate_score \u001b[38;5;241m=\u001b[39m bias_candidate_score\u001b[38;5;241m.\u001b[39mview( \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpratio\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    917\u001b[0m user_vec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_aware_user_encoder([x[\u001b[38;5;241m4\u001b[39m], x[\u001b[38;5;241m5\u001b[39m]])\n\u001b[1;32m--> 918\u001b[0m rel_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_vecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    921\u001b[0m     rel_scores[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mmul(candidate_vecs[i],user_vec[i]), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "val_metrics_epoch = []\n",
    "num_epochs = 10\n",
    "# Step 2: Create your Adam optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 3: Iterate over the data for the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "# Step 4: Iterate over each batch of data and compute the scores using the forward pass of the network\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x= [i.to(device) for i in x]\n",
    "        y = y.to(device)\n",
    "        out = model(x)\n",
    "    \n",
    "        # Step 5: Compute the lambda gradient values for the pairwise loss (spedup) with the compute_lambda_i method on the scores and the output labels\n",
    "        loss = loss_fn(out, y)\n",
    "\n",
    "        # Step 6: Bacward from the scores with the use of the lambda gradient values\n",
    "        if loss is not None:\n",
    "            # torch.autograd.backward(out, loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Step 7: Update the weights using the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_metrics = eval_model(model_config, News, user_encoder, val_impressions, val_user_data, val_userids,\n",
    "               news_encoder, bias_news_encoder, activity_gater, time_embedding_layer, \n",
    "               bias_content_scorer, scaler, colds, topKs, ValidUsers, device)\n",
    "    \n",
    "    print(\"epoch: {}, metrics: {}\".format(epoch, val_metrics))\n",
    "    val_metrics_epoch.append(val_metrics)\n",
    "\n",
    "    if epoch > 1:\n",
    "        if (val_metrics_epoch[-1][0] < val_metrics_epoch[-2][0]):\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T20:44:33.872428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 0, 7: 1, 10: 2, 15: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12678/12678 [09:56<00:00, 21.26it/s]\n"
     ]
    }
   ],
   "source": [
    "colds = [5, 7, 10, 15]\n",
    "topKs = 10\n",
    "test_metrics, test_cold_metrics, test_topics, test_ILADs, test_ILMDs = eval_model(model_config, News, user_encoder, test_impressions, test_user_data, test_userids,\n",
    "               news_encoder, bias_news_encoder, activity_gater, time_embedding_layer, \n",
    "               bias_content_scorer, scaler, colds, topKs, TestUsers, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val metrics []\n",
      "test metrics [0.6634010468600947, 0.4522433731561524, 0.5000726062253267, 0.554345353995634]\n",
      "cold [[0.6631188748709034, 0.6594726072544687, 0.548941892321481, 0.6636733228644994], [0.42642099280030316, 0.3334796925342455, 0.3155838143338143, 0.45982142857142855], [0.4664161142940799, 0.3930518848560765, 0.359610683584375, 0.5115775579644578], [0.5256374857231534, 0.4483332575556277, 0.42945446810269333, 0.5673416717378086]]\n",
      "diversity [[-7.851376934445681e-09, 0.3058020994337524, 0.40556908791317964, 0.453821723018089, 0.4803567541277471, 0.49424605803791327, 0.5020613400252352, 0.5062891028011648, 0.5087711844539807, 0.5102065742006435], [0.9999999921486231, 0.6116042091166076, 0.5191388283289838, 0.47957104162888525, 0.4561223003799973, 0.44408288730875817, 0.43646860975518853, 0.43145813391324866, 0.4280776474463261, 0.4259116095988076]]\n"
     ]
    }
   ],
   "source": [
    "print(\"val metrics\", val_metrics_epoch)\n",
    "print(\"test metrics\", test_metrics)\n",
    "print(\"cold\", test_cold_metrics)\n",
    "print(\"diversity\", [test_ILADs, test_ILMDs])\n",
    "\n",
    "results = {\"config\": config,\n",
    "           \"model_config\" : model_config,\n",
    "            \"val metrics\": val_metrics_epoch, \n",
    "           \"test metrics\": test_metrics,\n",
    "           \"cold\": test_cold_metrics,\n",
    "           \"diversity\": [test_ILADs, test_ILMDs]}\n",
    "\n",
    "import json\n",
    "with open('results{}.json'.format(time.time()), 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished\n",
    "## ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
