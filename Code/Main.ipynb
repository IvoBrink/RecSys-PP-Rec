{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T07:58:56.802485Z",
     "start_time": "2024-06-11T07:58:50.812875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NewsContent import *\n",
    "from UserContent import *\n",
    "from preprocessing import *\n",
    "from PEGenerator import *\n",
    "import PEGenerator\n",
    "from models import *\n",
    "from utils import *\n",
    "from Encoders import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T07:58:58.257584Z",
     "start_time": "2024-06-11T07:58:58.059586Z"
    }
   },
   "outputs": [],
   "source": [
    "data_root_path = \"../data/Challenge/\"\n",
    "embedding_path = \"../../\"\n",
    "KG_root_path = None\n",
    "popularity_path = \"../data/Challenge/popularity\"\n",
    "config = {'title_length':30,\n",
    "              'body_length':100,\n",
    "              'max_clicked_news':50,\n",
    "              'npratio':1,\n",
    "              'news_encoder_name':\"CNN\",\n",
    "              'user_encoder_name':\"Att\",\n",
    "             'attrs':['title','body','vert'],\n",
    "             'word_filter':0,\n",
    "             'data_root_path':data_root_path,\n",
    "             'embedding_path':embedding_path,\n",
    "             'KG_root_path':KG_root_path,\n",
    "            'popularity_path':popularity_path,\n",
    "            'batch_size': 32,\n",
    "             'max_entity_num':5}\n",
    "model_config = {\n",
    "        'news_encoder':0,\n",
    "        'popularity_user_modeling':True,\n",
    "        'rel':True,\n",
    "        'ctr':True,\n",
    "        'content':True,\n",
    "        'rece_emb':True,\n",
    "        'activity':True\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T08:35:17.505202Z",
     "start_time": "2024-06-11T08:35:16.705203Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19779\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m_zmq.py:141\u001b[0m, in \u001b[0;36mzmq.backend.cython._zmq._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython._zmq.Frame.__del__'\n",
      "Traceback (most recent call last):\n",
      "  File \"_zmq.py\", line 141, in zmq.backend.cython._zmq._check_rc\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2472\n",
      "2473\n"
     ]
    }
   ],
   "source": [
    "News = NewsContent(config)\n",
    "\n",
    "TrainUsers = UserContent(News.news_index,config,'train.tsv',2)\n",
    "ValidUsers = UserContent(News.news_index,config,'val.tsv',1)\n",
    "TestUsers = UserContent(News.news_index,config,'test.tsv',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19779\n",
      "19916\n",
      "2473\n",
      "2472\n"
     ]
    }
   ],
   "source": [
    "train_sess,train_buckets, train_user_id, train_label = get_train_input(TrainUsers.session,News.news_index,config)\n",
    "test_impressions, test_userids = get_test_input(TestUsers.session,News.news_index)\n",
    "val_impressions, val_userids = get_test_input(ValidUsers.session,News.news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_word_embedding_matrix, have_word = load_matrix(embedding_path,News.word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = TrainDataset(News, TrainUsers, train_sess, train_user_id, train_buckets, train_label, config['batch_size'])\n",
    "test_user_generator = UserDataset(News,TestUsers, config['batch_size'])\n",
    "val_user_generator = UserDataset(News,ValidUsers, config['batch_size'])\n",
    "news_generator = NewsDataset(News, config['batch_size'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "623"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor([ 4, 23, 15, 44, 45, 45, 45,  1,  1, 18, 43,  2,  0, 10,  5,  1,  1,  0,\n",
      "         5,  4, 13, 13, 13, 31, 20, 20, 20, 20, 20, 20, 20, 20],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(type(x[3]), x[3])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135960, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_word_embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = \\\n",
    "create_pe_model(config, model_config, News, title_word_embedding_matrix, entity_embedding_matrix=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0016051364365971107\n",
      "torch.Size([160, 400])\n",
      "torch.Size([160, 1])\n",
      "torch.Size([160])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'news_scoring' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m     time_embedding_matrix \u001b[38;5;241m=\u001b[39m time_embedding_layer\u001b[38;5;241m.\u001b[39mweight\n\u001b[0;32m     62\u001b[0m     ctr_weight \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mscaler[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 63\u001b[0m     val_rankings \u001b[38;5;241m=\u001b[39m news_ranking(model_config, ctr_weight, val_predicted_activity_gates, val_user_scoring, \u001b[43mnews_scoring\u001b[49m, \n\u001b[0;32m     64\u001b[0m                                bias_candidate_score, news_bias_vecs, time_embedding_matrix, bias_content_scorer,\n\u001b[0;32m     65\u001b[0m                                News,val_impressions)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m#     train_metrics = evaluate_model(data, model.forward, 'train')\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m#     val_metrics = evaluate_model(data, model.forward, 'validation')\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m#     \"metrics_val\": val_metrics_epoch\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'news_scoring' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "val_metrics_epoch = []\n",
    "num_epochs = 1\n",
    "# Step 2: Create your Adam optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 3: Iterate over the data for the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Step 4: Iterate over each batch of data and compute the scores using the forward pass of the network\n",
    "    model.train()\n",
    "    i = 0\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "    \n",
    "        # Step 5: Compute the lambda gradient values for the pairwise loss (spedup) with the compute_lambda_i method on the scores and the output labels\n",
    "        loss = loss_fn(out, y)\n",
    "\n",
    "        # Step 6: Bacward from the scores with the use of the lambda gradient values\n",
    "        if loss is not None:\n",
    "            # torch.autograd.backward(out, loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Step 7: Update the weights using the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "    # Step 8: At the end of the epoch, evaluate the model on the data using the evaluate_model function (both train and val)\n",
    "    model.eval()\n",
    "\n",
    "    news_scoring = []\n",
    "    news_bias_vecs = []\n",
    "    for x in news_generator:\n",
    "        news_scoring.append(news_encoder(x))\n",
    "        news_bias_vecs.append(bias_news_encoder(x))\n",
    "    news_scoring = torch.cat(news_scoring, dim = 0)\n",
    "    news_bias_vecs = torch.cat(news_bias_vecs, dim = 0)\n",
    "\n",
    "    val_user_scoring = []\n",
    "    for x, y in val_user_generator:\n",
    "        val_user_scoring.append(user_encoder((x, y)))\n",
    "    val_user_scoring = torch.cat(val_user_scoring, dim = 0)\n",
    "    \n",
    "    val_predicted_activity_gates = activity_gater(val_user_scoring)\n",
    "    val_predicted_activity_gates = val_predicted_activity_gates[:,0]\n",
    "\n",
    "    bias_candidate_score = 0\n",
    "\n",
    "    time_embedding_matrix = time_embedding_layer.weight\n",
    "    ctr_weight = scaler.scaler[0]\n",
    "    val_rankings = news_ranking(model_config, ctr_weight, val_predicted_activity_gates, val_user_scoring, news_scoring, \n",
    "                               bias_candidate_score, news_bias_vecs, time_embedding_matrix, bias_content_scorer,\n",
    "                               News,val_impressions)\n",
    "    \n",
    "    val_metrics = evaluate_performance(val_rankings,val_impressions)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - , Val Metrics: {val_metrics}\")\n",
    "\n",
    "#     # Step 9: Append the metrics to val_metrics_epoch\n",
    "    val_metrics_epoch.append(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news_scoring = []\n",
    "news_bias_vecs = []\n",
    "for x in news_generator:\n",
    "    news_scoring.append(news_encoder(x))\n",
    "    news_bias_vecs.append(bias_news_encoder(x))\n",
    "news_scoring = torch.cat(news_scoring, dim = 0)\n",
    "news_bias_vecs = torch.cat(news_bias_vecs, dim = 0)\n",
    "\n",
    "test_user_scoring = []\n",
    "for x, y in test_user_generator:\n",
    "    test_user_scoring.append(user_encoder((x, y)))\n",
    "test_user_scoring = torch.cat(test_user_scoring, dim = 0)\n",
    "\n",
    "test_predicted_activity_gates = activity_gater(test_user_scoring)\n",
    "test_predicted_activity_gates = test_predicted_activity_gates[:,0]\n",
    "\n",
    "rankings = news_ranking(model_config,ctr_weight,test_predicted_activity_gates,test_user_scoring,news_scoring,\n",
    "                                bias_candidate_score,news_bias_vecs,time_embedding_matrix,bias_content_scorer,\n",
    "                                News,test_impressions)\n",
    "performance = evaluate_performance(rankings,test_impressions)\n",
    "\n",
    "cold = []\n",
    "for TOP_COLD_NUM in [0,1,3,5,]:\n",
    "    g = evaluate_cold_users(rankings,test_impressions,TestUsers.click,TOP_COLD_NUM)\n",
    "    cold.append(g)\n",
    "diversity = []\n",
    "for TOP_DIVERSITY_NUM in range(1,11):\n",
    "    div_top = evaluate_diversity_topic_all(TOP_DIVERSITY_NUM,rankings,test_impressions,News,TestUsers)\n",
    "    div_ilxd = evaluate_density_ILxD(TOP_DIVERSITY_NUM,rankings,test_impressions,news_scoring)\n",
    "    diversity.append([div_top,div_ilxd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"val metrics\", val_metrics_epoch)\n",
    "print(\"test metrics\", performance)\n",
    "print(\"cold\", cold)\n",
    "print(\"diversity\", diversity)\n",
    "\n",
    "results = {\"val metrics\": val_metrics_epoch, \n",
    "           \"test metrics\": performance,\n",
    "           \"cold\": cold,\n",
    "           \"diversity\": diversity}\n",
    "\n",
    "import json\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished\n",
    "## ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-11T07:59:00.558967Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.compile(loss=['categorical_crossentropy'],\n",
    "#                   optimizer=Adam(lr=0.0001), \n",
    "#                   metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-11T07:59:00.560967Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NewsContent' object has no attribute 'entity_embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater \u001b[38;5;241m=\u001b[39m create_pe_model(config,model_config,News,title_word_embedding_matrix,\u001b[43mNews\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentity_embedding\u001b[49m)\n\u001b[0;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit_generator(train_generator,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      5\u001b[0m     news_scoring \u001b[38;5;241m=\u001b[39m news_encoder\u001b[38;5;241m.\u001b[39mpredict_generator(news_generator,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NewsContent' object has no attribute 'entity_embedding'"
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "\n",
    "#     model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = create_pe_model(config,model_config,News,title_word_embedding_matrix,News.entity_embedding)\n",
    "#     model.fit_generator(train_generator,epochs=2)\n",
    "#     news_scoring = news_encoder.predict_generator(news_generator,verbose=True)\n",
    "#     user_scoring = user_encoder.predict_generator(test_user_generator,verbose=True)\n",
    "#     val_user_scoring = user_encoder.predict_generator(val_user_generator,verbose=True)\n",
    "\n",
    "\n",
    "#     news_bias_vecs = bias_news_encoder.predict_generator(news_generator,verbose=True)\n",
    "\n",
    "#     if model_config['content'] and not model_config['rece_emb']:\n",
    "#         bias_candidate_score = bias_content_scorer.predict(news_bias_vecs,batch_size=32,verbose=True)\n",
    "#         bias_candidate_score = bias_candidate_score[:,0]\n",
    "#     else:\n",
    "#         bias_candidate_score = 0\n",
    "\n",
    "#     ctr_weight = scaler.get_weights()[0][0,0]\n",
    "#     time_embedding_matrix = time_embedding_layer.get_weights()[0]\n",
    "    \n",
    "#     predicted_activity_gates = activity_gater.predict(user_scoring,verbose=True)\n",
    "#     predicted_activity_gates = predicted_activity_gates[:,0]\n",
    "    \n",
    "#     val_predicted_activity_gates = activity_gater.predict(val_user_scoring,verbose=True)\n",
    "#     val_predicted_activity_gates = val_predicted_activity_gates[:,0]\n",
    "    \n",
    "#     rankings = news_ranking(model_config,ctr_weight,predicted_activity_gates,user_scoring,news_scoring,\n",
    "#                                 bias_candidate_score,news_bias_vecs,time_embedding_matrix,bias_content_scorer,\n",
    "#                                 News,test_impressions)\n",
    "    \n",
    "#     val_rankings = news_ranking(model_config,ctr_weight,val_predicted_activity_gates,val_user_scoring,news_scoring,\n",
    "#                                bias_candidate_score,news_bias_vecs,time_embedding_matrix,bias_content_scorer,\n",
    "#                                News,val_impressions)\n",
    "    \n",
    "#     performance = evaluate_performance(rankings,test_impressions)\n",
    "#     val_performance = evaluate_performance(val_rankings,val_impressions)\n",
    "\n",
    "#     cold = []\n",
    "#     for TOP_COLD_NUM in [0,1,3,5,]:\n",
    "#         g = evaluate_cold_users(rankings,test_impressions,TestUsers.click,TOP_COLD_NUM)\n",
    "#         cold.append(g)\n",
    "#     diversity = []\n",
    "#     for TOP_DIVERSITY_NUM in range(1,11):\n",
    "#         div_top = evaluate_diversity_topic_all(TOP_DIVERSITY_NUM,rankings,test_impressions,News,TestUsers)\n",
    "#         div_ilxd = evaluate_density_ILxD(TOP_DIVERSITY_NUM,rankings,test_impressions,news_scoring)\n",
    "#         diversity.append([div_top,div_ilxd])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
