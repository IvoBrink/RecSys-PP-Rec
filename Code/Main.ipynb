{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:44:51.052648Z",
     "start_time": "2024-06-23T20:44:43.498034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NewsContent import *\n",
    "from UserContent import *\n",
    "from preprocessing import *\n",
    "from PEGenerator import *\n",
    "import PEGenerator\n",
    "from models import *\n",
    "from utils import *\n",
    "from Encoders import *\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:44:51.286650Z",
     "start_time": "2024-06-23T20:44:51.054656Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:44:51.475649Z",
     "start_time": "2024-06-23T20:44:51.288661Z"
    }
   },
   "outputs": [],
   "source": [
    "data_root_path = \"../data/Challenge/\"\n",
    "embedding_path = \"../../\"\n",
    "KG_root_path = \"../data/Challenge/entity\"\n",
    "popularity_path = \"../data/Challenge/popularity\"\n",
    "config = {'title_length':30,\n",
    "              'body_length':100,\n",
    "              'max_clicked_news':50,\n",
    "              'npratio':1,\n",
    "              'news_encoder_name':\"CNN\",\n",
    "              'user_encoder_name':\"Att\",\n",
    "             'attrs':['title', 'entity','vert'],\n",
    "             'word_filter':0,\n",
    "             'data_root_path':data_root_path,\n",
    "             'embedding_path':embedding_path,\n",
    "             'KG_root_path':KG_root_path,\n",
    "            'popularity_path':popularity_path,\n",
    "            'batch_size': 32,\n",
    "             'max_entity_num':5}\n",
    "model_config = {\n",
    "        'news_encoder':1,\n",
    "        'popularity_user_modeling':True,\n",
    "        'rel':True,\n",
    "        'ctr':True,\n",
    "        'content':True,\n",
    "        'rece_emb':True,\n",
    "        'activity':True\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:45:10.721551Z",
     "start_time": "2024-06-23T20:44:51.477650Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24724\n",
      "12678\n",
      "12678\n"
     ]
    }
   ],
   "source": [
    "News = NewsContent(config)\n",
    "\n",
    "TrainUsers = UserContent(News.news_index,config,'train.tsv',2)\n",
    "ValidUsers = UserContent(News.news_index,config,'val.tsv',1)\n",
    "TestUsers = UserContent(News.news_index,config,'test.tsv',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:45:11.050558Z",
     "start_time": "2024-06-23T20:45:10.724553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24724\n",
      "24888\n",
      "12678\n",
      "12678\n"
     ]
    }
   ],
   "source": [
    "train_sess,train_buckets, train_user_id, train_label = get_train_input(TrainUsers.session,News.news_index,config)\n",
    "test_impressions, test_userids = get_test_input(TestUsers.session,News.news_index)\n",
    "val_impressions, val_userids = get_test_input(ValidUsers.session,News.news_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:18.998182Z",
     "start_time": "2024-06-23T20:45:11.052559Z"
    }
   },
   "outputs": [],
   "source": [
    "title_word_embedding_matrix, have_word = load_matrix(embedding_path,News.word_dict)\n",
    "entity_embedding_matrix, have_word2 = load_matrix(embedding_path, News.entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:19.268181Z",
     "start_time": "2024-06-23T20:46:18.999184Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TrainDataset(News, TrainUsers, train_sess, train_user_id, train_buckets, train_label), config['batch_size'])\n",
    "val_user_data = UserDataset(News,ValidUsers)\n",
    "test_user_data = UserDataset(News,TestUsers)\n",
    "news_data = NewsDataset(News)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:46:20.073213Z",
     "start_time": "2024-06-23T20:46:19.522203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved news_encoder to cuda\n",
      "Moved bias_news_encoder to cuda\n",
      "Moved pop_aware_user_encoder to cuda\n",
      "Moved bias_scorer to cuda\n",
      "Moved activity_gater to cuda\n",
      "Moved time_embedding_layer to cuda\n",
      "Moved time_distributed1 to cuda\n",
      "Moved time_distributed2 to cuda\n",
      "Moved time_distributed3 to cuda\n",
      "Moved scaler to cuda\n",
      "Moved softmax to cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "model,user_encoder,news_encoder,bias_news_encoder,bias_content_scorer,scaler,time_embedding_layer,activity_gater = \\\n",
    "create_pe_model(config, model_config, News, title_word_embedding_matrix, entity_embedding_matrix, device)\n",
    "\n",
    "model.to(device)\n",
    "for name, module in model.named_children():\n",
    "    module.to(device)\n",
    "    print(f'Moved {name} to {device}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "colds = [0,1,3,5]\n",
    "topKs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T20:47:51.941698Z",
     "start_time": "2024-06-23T20:46:20.266217Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 482/778 [06:34<04:02,  1.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Step 6: Bacward from the scores with the use of the lambda gradient values\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# torch.autograd.backward(out, loss)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Step 7: Update the weights using the optimizer\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tangs\\Documents\\uni_stuff\\RecSys\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "val_metrics_epoch = []\n",
    "num_epochs = 10\n",
    "# Step 2: Create your Adam optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 3: Iterate over the data for the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "# Step 4: Iterate over each batch of data and compute the scores using the forward pass of the network\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x= [i.to(device) for i in x]\n",
    "        y = y.to(device)\n",
    "        out = model(x)\n",
    "    \n",
    "        # Step 5: Compute the lambda gradient values for the pairwise loss (spedup) with the compute_lambda_i method on the scores and the output labels\n",
    "        loss = loss_fn(out, y)\n",
    "\n",
    "        # Step 6: Bacward from the scores with the use of the lambda gradient values\n",
    "        if loss is not None:\n",
    "            # torch.autograd.backward(out, loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Step 7: Update the weights using the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    val_metrics = eval_model(model_config, News, user_encoder, val_impressions, val_user_data, val_userids,\n",
    "               news_encoder, bias_news_encoder, activity_gater, time_embedding_layer, \n",
    "               bias_content_scorer, scaler, colds, topKs, ValidUsers, device)\n",
    "    \n",
    "    print(\"epoch: {}, metrics: {}\".format(epoch, val_metrics))\n",
    "    val_metrics_epoch.append(val_metrics)\n",
    "\n",
    "    if epoch > 1:\n",
    "        if (val_metrics_epoch[-1][0] < val_metrics_epoch[-2][0]):\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-23T20:44:33.872428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 0, 7: 1, 10: 2, 15: 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12678/12678 [08:46<00:00, 24.08it/s]\n"
     ]
    }
   ],
   "source": [
    "colds = [5, 7, 10, 15]\n",
    "topKs = 10\n",
    "test_metrics, test_cold_metrics, test_topics, test_ILADs, test_ILMDs = eval_model(model_config, News, user_encoder, test_impressions, test_user_data, test_userids,\n",
    "               news_encoder, bias_news_encoder, activity_gater, time_embedding_layer, \n",
    "               bias_content_scorer, scaler, colds, topKs, TestUsers, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val metrics []\n",
      "test metrics [0.627484895393094, 0.4297519571039034, 0.4753759853071009, 0.532778965387273]\n",
      "cold [[0.6138236129995766, 0.6254345972302675, 0.5990490156926468, 0.7041981439040264], [0.3864736170166459, 0.36747022817572456, 0.37655225172506274, 0.5105208333333334], [0.44226945238035353, 0.42599310038008287, 0.37769428374867087, 0.5925160023561062], [0.48548765628458385, 0.4562007137085822, 0.49396254935706174, 0.6073579684856072]]\n",
      "diversity [[-7.917196860842232e-09, 0.3013567264372664, 0.403274080861083, 0.45224445247277795, 0.4812585652006182, 0.496932740466492, 0.5060075053724511, 0.5112391858940377, 0.5146283361414927, 0.5167912913856305], [0.9999999920828031, 0.6027134624066686, 0.5269909317461657, 0.495102463770522, 0.4764904366798216, 0.4664966762818115, 0.4603120922069103, 0.4564619253798414, 0.4536710050903786, 0.45165393802763854]]\n"
     ]
    }
   ],
   "source": [
    "print(\"val metrics\", val_metrics_epoch)\n",
    "print(\"test metrics\", test_metrics)\n",
    "print(\"cold\", test_cold_metrics)\n",
    "print(\"diversity\", [test_ILADs, test_ILMDs])\n",
    "\n",
    "results = {\"config\": config,\n",
    "           \"model_config\" : model_config,\n",
    "            \"val metrics\": val_metrics_epoch, \n",
    "           \"test metrics\": test_metrics,\n",
    "           \"cold\": test_cold_metrics,\n",
    "           \"diversity\": [test_ILADs, test_ILMDs]}\n",
    "\n",
    "import json\n",
    "with open('results{}.json'.format(time.time()), 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished\n",
    "## ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
